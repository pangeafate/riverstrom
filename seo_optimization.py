#!/usr/bin/env python3
"""
SEO optimization script - adds SEO elements without touching layout or structure
"""

import os
import glob
import re
from datetime import datetime

def create_seo_meta_tags():
    """Create SEO meta tags to insert into head section"""
    return '''
    <!-- SEO Meta Tags -->
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <meta name="language" content="ru">
    <meta name="author" content="Riverstrom AI">
    <meta name="keywords" content="AI, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, on-premise, –Ω–µ-–æ–±–ª–∞—á–Ω—ã–π AI, Riverstrom">
    
    <!-- Open Graph Meta Tags -->
    <meta property="og:site_name" content="Riverstrom AI">
    <meta property="og:locale" content="ru_RU">
    <meta property="og:url" content="https://riverstrom.ai/">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:site" content="@riverstrom">
    <meta name="twitter:creator" content="@riverstrom">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://riverstrom.ai/">'''

def create_structured_data():
    """Create JSON-LD structured data"""
    return '''
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Organization",
        "name": "Riverstrom AI",
        "url": "https://riverstrom.ai",
        "description": "–ù–µ-–æ–±–ª–∞—á–Ω—ã–π –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ AI –º–æ–¥–µ–ª–µ–π on-premise",
        "foundingDate": "2024",
        "contactPoint": {
            "@type": "ContactPoint",
            "contactType": "sales",
            "url": "https://riverstrom.ai/contact/"
        },
        "sameAs": [
            "https://github.com/pangeafate/riverstrom"
        ]
    }
    </script>'''

def get_page_specific_seo(page_path):
    """Get page-specific SEO data"""
    
    page_configs = {
        'page.html': {
            'title': 'Riverstrom AI - –ù–µ-–æ–±–ª–∞—á–Ω—ã–π –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç',
            'description': '–ù–µ-–æ–±–ª–∞—á–Ω—ã–π –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ AI –º–æ–¥–µ–ª–µ–π on-premise. –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.',
            'url': '/',
            'keywords': 'AI, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, machine learning, on-premise AI, –Ω–µ-–æ–±–ª–∞—á–Ω—ã–π AI'
        },
        'products/page.html': {
            'title': '–ü—Ä–æ–¥—É–∫—Ç—ã - Riverstrom AI',
            'description': '–ù–∞—à–∏ –ø—Ä–æ–¥—É–∫—Ç—ã –¥–ª—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –†–µ—à–µ–Ω–∏—è on-premise –¥–ª—è –≤–∞—à–µ–≥–æ –±–∏–∑–Ω–µ—Å–∞.',
            'url': '/products/',
            'keywords': 'AI –ø—Ä–æ–¥—É–∫—Ç—ã, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, hardware, on-premise —Ä–µ—à–µ–Ω–∏—è'
        },
        'solutions/page.html': {
            'title': '–†–µ—à–µ–Ω–∏—è - Riverstrom AI',
            'description': '–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ç—Ä–∞—Å–ª–µ–π. –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ AI.',
            'url': '/solutions/',
            'keywords': 'AI —Ä–µ—à–µ–Ω–∏—è, –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏, –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞'
        },
        'prices/page.html': {
            'title': '–¶–µ–Ω—ã - Riverstrom AI',
            'description': '–ü—Ä–æ–∑—Ä–∞—á–Ω—ã–µ —Ü–µ–Ω—ã –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç—ã –∏ —É—Å–ª—É–≥–∏ Riverstrom AI. –°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.',
            'url': '/prices/',
            'keywords': '—Ü–µ–Ω—ã AI, —Å—Ç–æ–∏–º–æ—Å—Ç—å, –ø—Ä–∞–π—Å-–ª–∏—Å—Ç, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'
        },
        'contact/page.html': {
            'title': '–ö–æ–Ω—Ç–∞–∫—Ç—ã - Riverstrom AI',
            'description': '–°–≤—è–∂–∏—Ç–µ—Å—å —Å –∫–æ–º–∞–Ω–¥–æ–π Riverstrom AI. –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.',
            'url': '/contact/',
            'keywords': '–∫–æ–Ω—Ç–∞–∫—Ç—ã, —Å–≤—è–∑–∞—Ç—å—Å—è, –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è AI, –ø–æ–¥–¥–µ—Ä–∂–∫–∞'
        },
        'blogs/page.html': {
            'title': '–ë–ª–æ–≥ - Riverstrom AI',
            'description': '–°—Ç–∞—Ç—å–∏ –∏ –Ω–æ–≤–æ—Å—Ç–∏ –æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ, –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö AI.',
            'url': '/blogs/',
            'keywords': '–±–ª–æ–≥ AI, —Å—Ç–∞—Ç—å–∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –Ω–æ–≤–æ—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç'
        }
    }
    
    # Default for blog articles
    default_blog = {
        'title': '–°—Ç–∞—Ç—å—è - Riverstrom AI',
        'description': '–°—Ç–∞—Ç—å—è –æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ –∏ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –æ—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ Riverstrom AI.',
        'url': f'/blogs/{os.path.basename(os.path.dirname(page_path))}/',
        'keywords': 'AI —Å—Ç–∞—Ç—å—è, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'
    }
    
    return page_configs.get(page_path, default_blog)

def add_seo_to_html(html_file):
    """Add SEO elements to HTML file without touching existing structure"""
    
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # Get page-specific SEO data
        page_info = get_page_specific_seo(html_file)
        
        # Only add SEO if not already present
        if '<!-- SEO Meta Tags -->' in content:
            print(f"SEO already present in {html_file}")
            return False
        
        # Find the closing </head> tag to insert before it
        head_close_match = re.search(r'</head>', content, re.IGNORECASE)
        if not head_close_match:
            print(f"No </head> tag found in {html_file}")
            return False
        
        # Create SEO content
        seo_meta = create_seo_meta_tags()
        
        # Update canonical URL for specific pages
        if html_file != 'page.html':
            seo_meta = seo_meta.replace('https://riverstrom.ai/', f'https://riverstrom.ai{page_info["url"]}')
        
        # Add page-specific meta tags
        page_specific_meta = f'''
    <meta name="description" content="{page_info['description']}">
    <meta name="keywords" content="{page_info['keywords']}">
    <meta property="og:title" content="{page_info['title']}">
    <meta property="og:description" content="{page_info['description']}">
    <meta property="og:url" content="https://riverstrom.ai{page_info['url']}">
    <meta name="twitter:title" content="{page_info['title']}">
    <meta name="twitter:description" content="{page_info['description']}">'''
        
        structured_data = create_structured_data()
        
        # Insert SEO content before </head>
        insert_pos = head_close_match.start()
        new_content = (content[:insert_pos] + 
                      seo_meta + 
                      page_specific_meta + 
                      structured_data + '\n    ' +
                      content[insert_pos:])
        
        # Write the updated content
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"‚úÖ Added SEO to {html_file}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error processing {html_file}: {e}")
        return False

def create_sitemap():
    """Create XML sitemap"""
    
    pages = [
        {'url': '/', 'priority': '1.0'},
        {'url': '/products/', 'priority': '0.8'},
        {'url': '/solutions/', 'priority': '0.8'},
        {'url': '/prices/', 'priority': '0.7'},
        {'url': '/contact/', 'priority': '0.7'},
        {'url': '/blogs/', 'priority': '0.6'},
        {'url': '/blogs/a7130d/', 'priority': '0.5'},
        {'url': '/blogs/a8236/', 'priority': '0.5'},
        {'url': '/blogs/h7230d/', 'priority': '0.5'},
        {'url': '/blogs/ais07/', 'priority': '0.5'},
        {'url': '/blogs/a7135d/', 'priority': '0.5'},
        {'url': '/blogs/a7230x/', 'priority': '0.5'}
    ]
    
    lastmod = datetime.now().strftime('%Y-%m-%d')
    
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
    sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    
    for page in pages:
        sitemap_content += f'''  <url>
    <loc>https://riverstrom.ai{page['url']}</loc>
    <lastmod>{lastmod}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>{page['priority']}</priority>
  </url>
'''
    
    sitemap_content += '</urlset>'
    
    with open('sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    
    print("‚úÖ Created sitemap.xml")

def create_robots_txt():
    """Create robots.txt file"""
    
    robots_content = '''User-agent: *
Allow: /

# Sitemaps
Sitemap: https://riverstrom.ai/sitemap.xml

# Crawl-delay
Crawl-delay: 1'''
    
    with open('robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("‚úÖ Created robots.txt")

def main():
    """Main function to add SEO optimization"""
    
    print("üöÄ Starting SEO optimization...")
    print("‚ö†Ô∏è  Only adding SEO elements - no layout changes!")
    
    # Find all HTML files
    html_files = []
    for pattern in ['*.html', '*/*.html', '*/*/*.html']:
        html_files.extend(glob.glob(pattern))
    
    # Remove index.html from processing (it's just a redirect)
    html_files = [f for f in html_files if f != 'index.html']
    
    print(f"\nüîç Found {len(html_files)} HTML files to optimize")
    
    # Add SEO to HTML files
    updated_count = 0
    for html_file in html_files:
        if add_seo_to_html(html_file):
            updated_count += 1
    
    # Create SEO files
    create_sitemap()
    create_robots_txt()
    
    print(f"\nüéâ SEO optimization complete!")
    print(f"üìù Updated {updated_count} HTML files with SEO")
    print(f"üìÑ Created sitemap.xml and robots.txt")
    print("‚úÖ Original layout and structure preserved")

if __name__ == "__main__":
    main()